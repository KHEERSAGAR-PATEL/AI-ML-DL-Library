

---

## ðŸ§  Lightweight ML/DL Library Engineered from Scratch

> A self-built, scalable machine learning and deep learning library written from the ground up â€” **no TensorFlow, no PyTorch**, just raw mathematics and engineering.

This project demonstrates the **fundamental mechanics of ML and DL systems**, implemented with precision and optimized for **speed, memory efficiency**, and **extensibility**. The models and optimizers have been rigorously validated on real datasets and show performance **within 5% of state-of-the-art frameworks** like TensorFlow and PyTorch.

---

## ðŸ” Project Objectives

- âœ… Build a **minimal yet expressive ML/DL framework** from first principles  
- ðŸ§  Reinforce understanding of the **mathematics behind training dynamics**  
- ðŸ’¾ Design for a **lightweight memory footprint**, avoiding unnecessary overhead  
- ðŸš€ Optimize for **speed and generalization**, with extensibility in mind  

---

## âš™ï¸ Features

### ðŸ”§ ML Algorithms
- Linear Regression / Logistic Regression  
- K-Nearest Neighbors  
- Naive Bayes  
- Support Vector Machine (SVM), and more  

### ðŸ” Optimization Engines
- Gradient Descent (GD)  
- Stochastic Gradient Descent (SGD)  
- Momentum  
- Adam Optimizer (manual implementation), and more  

### ðŸ§± Deep Learning Components
- RNN, LSTM ,GRU from scratch implementation
- Dense Layers  
- ReLU / Sigmoid / Tanh Activations  
- Loss Functions: MSE, Binary Cross-Entropy, Categorical Cross-Entropy  
- ...and more  

### ðŸ“Š Utilities
- Data Loaders  
- Mini-batching, Shuffling, One-hot Encoding  
- Accuracy, Precision, Recall, F1-score Evaluation  
- Model Checkpointing and Metric Logging  

---

## ðŸ§ª Benchmarks

> ðŸš€ All models were trained and evaluated **without using any external ML/DL libraries**.

Performance results show **<5% deviation from TensorFlow/PyTorch baselines** on standard datasets like MNIST, CIFAR-10 (on subset), and synthetic regression tasks.

---

## ðŸ› ï¸ Tech Stack

- **Python**
- **NumPy**
- **Matplotlib**
- Fully custom forward & backward propagation engine

---

## ðŸ§  Learning Outcomes

- ðŸ”¬ Deep understanding of **matrix calculus** and **gradient propagation**  
- ðŸ’¡ Ability to reason about **computational complexity and memory bottlenecks**  
- ðŸ—ï¸ Systems-level engineering: building everything from **optimizers to backpropagation**  

---

## ðŸ’¼ Use Cases

- âœ… Educational tool for teaching ML/DL internals  
- âœ… Research experiments in memory-constrained environments  
- âœ… Deployment in edge or embedded systems  
- âœ… Interview prep for systems/ML engineer roles  

---

## ðŸ‘¨â€ðŸ’» Author

**Kheer Sagar Patel**  
*M.Tech CSE (AI & ML), IIITDM Jabalpur*  
*Phd first sem @ IIT Bhilai*

---

## ðŸŒŸ Like this project?

If you're a recruiter or researcher interested in **system-level ML projects** or **custom optimization engines**, feel free to â­ the repo and connect!

---
